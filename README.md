[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18529821.svg)](https://doi.org/10.5281/zenodo.18529821)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Paper](https://img.shields.io/badge/Paper-PDF-red)](./papers/PAPER_KAPPA_LLM_EN.md)

# Kappa-LLM: Multi-Observable Structural Detection and Real-Time Mitigation of Hallucinations

*Kappa-Attention-Regimes ‚Äî empirical application of the Kappa Method to LLM attention dynamics*



Official implementation of **"Kappa-LLM: Multi-Observable Structural Detection and Real-Time Mitigation of Hallucinations in Large Language Models"** using topology-aware observables

<p align="center">
  <img src="./figures/framework/kappa_framework_overview.png" alt="Kappa-LLM Framework" width="800"/>
</p>

---

## üéØ **Overview**

Kappa-LLM is a multi-observable framework for detecting and mitigating hallucinations in Large Language Models (LLMs) during generation. Rather than post-hoc fact-checking, we monitor **structural attention dynamics** in real-time and prune unsafe trajectories before semantic failure.
This repository provides an empirical application of the **Kappa Method**
(see https://github.com/odavidohio/Kappa-Method) to attention dynamics in large language models.


### **Key Features**

‚úÖ **Real-Time Detection**: Monitors attention dynamics during generation (<2% overhead)  
‚úÖ **Multi-Observable Framework**: 5 canonical observables (Œ©, Œ¶, Œ∑, Œû, Œî) capture structural instability  
‚úÖ **Cross-Architecture**: Validated on Phi-3, Mistral-7B, Llama-3.1-8B  
‚úÖ **Production-Compatible**: Designed to integrate with HuggingFace `StoppingCriteria`
‚úÖ **Strong Performance**: 94.2% AUC (Phi-3), 85% accuracy, +36.5pp over baseline  

---

## üìä **Main Results**

| Model | Kappa AUC | Accuracy | R-Score AUC | Improvement |
|-------|-----------|----------|-------------|-------------|
| **Phi-3 Mini** | 94.2% | 85.0% | 57.7% | **+36.5pp** |
| **Mistral-7B** | 87.1% | 70.0% | 58.3% | **+28.8pp** |
| **Llama-3.1-8B** | 79.1% | 61.0% | 57.7% | **+21.4pp** |

**Computational Overhead:** <2% (10-15ms per checkpoint on A100)

> **Note:** Binary accuracy is bounded by architectural stability and is not the primary objective of the framework. The goal is structural risk detection, not semantic verification.

> ‚ö†Ô∏è API note: The real-time integration shown below reflects the intended
> interface for the first stable release. Current versions expose the detector
> as a scoring component over extracted attention windows.

---

## üöÄ **Quick Start**

### **Installation**

```bash
# Clone repository
git clone https://github.com/odavidohio/Kappa-Attention-Regimes.git
cd Kappa-Attention-Regimes

# Install dependencies
pip install -r requirements.txt

# Install package
pip install -e .
```

### **Basic Usage**

```python
from kappa_llm import KappaDetector
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load model
model = AutoModelForCausalLM.from_pretrained("microsoft/Phi-3-mini-4k-instruct")
tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")

# Initialize Kappa detector
detector = KappaDetector(
    model=model,
    window_size=10,
    check_interval=5,
    tau_abort=0.74,  # Phi-3 calibrated threshold
    persistence_k=2
)

# Generate with real-time monitoring
prompt = "What is the capital of France?"
outputs = model.generate(
    tokenizer.encode(prompt, return_tensors="pt"),
    max_length=100,
    stopping_criteria=[detector]
)

# Check if generation was pruned
if detector.was_pruned:
    print(f"‚ö†Ô∏è Generation pruned at token {detector.prune_position}")
    print(f"üìä Structural risk: {detector.final_risk:.3f}")
else:
    print(f"‚úÖ Generation completed safely")
    print(tokenizer.decode(outputs[0]))
```


## üìñ **Documentation**

### **Papers**

- üìÑ [English Paper](./papers/PAPER_KAPPA_LLM_EN.md) - Full methodological description
- üìÑ [Portuguese Paper](./papers/PAPER_KAPPA_LLM_PT.md) - Vers√£o completa em portugu√™s


## üîó **Related Work**

- **Kappa-Method** ‚Äî Theoretical foundation of the Kappa framework, defining
  the canonical observables (Œ©, Œ¶, Œ∑, Œû, Œî) and regime analysis used in this work.  
  https://github.com/odavidohio/Kappa-Method

### **Examples**

- üí° [Basic Usage](./examples/basic_usage.py)

---

## üß™ **Reproducing Experiments**

### **HaluEval Dataset**

```bash
# Download HaluEval dataset
python experiments/download_halueval.py

# Run experiments (Phi-3)
python experiments/halueval/run_phi3.py \
    --model microsoft/Phi-3-mini-4k-instruct \
    --output ./experiments/results/phi3/

# Run experiments (Mistral)
python experiments/halueval/run_mistral.py \
    --model mistralai/Mistral-7B-Instruct-v0.2 \
    --output ./experiments/results/mistral/

# Run experiments (Llama)
python experiments/halueval/run_llama.py \
    --model meta-llama/Llama-3.1-8B-Instruct \
    --output ./experiments/results/llama/
```

### **Generate Figures**

```bash
# Generate all paper figures
python experiments/generate_figures.py \
    --results_dir ./experiments/results/ \
    --output_dir ./papers/figures/
```

---

## üî¨ **Method Overview**

### **The Five Observables**

Kappa-LLM computes five canonical observables from attention matrices:

| Observable | Symbol | Measures | AUC (Phi-3) |
|------------|--------|----------|-------------|
| **Entropy** | Œ© | Attention mass distribution | 93.1% |
| **Persistence** | Œ¶ | Topological structure (0-dim holes) | 58.0% |
| **Rigidity** | Œ∑ | Semantic alignment stability | 93.1% |
| **Diversity** | Œû | Head specialization | 69.3% |
| **Divergence** | Œî | Structural deviation from baseline | 93.1% |

### **Kappa Score**

```python
# Composite score combining all observables
K(t) = sigmoid(
    Œ±_Œ© ¬∑ (1 - Œ©(t)) +
    Œ±_Œ¶ ¬∑ Œ¶(t) +
    Œ±_Œ∑ ¬∑ Œ∑(t) +
    Œ±_Œû ¬∑ (1 - Œû(t)) +
    Œ±_Œî ¬∑ Œî(t)
)
```

### **Real-Time Pruning**

Uses **second-order statistics** (observable variability) for early detection:

```python
# Structural risk estimation
R(t) = sigmoid(
    Œ±_Œ∑ ¬∑ œÉ_Œ∑(t) +  # Rigidity std
    Œ±_œâ ¬∑ œÉ_œâ(t) +  # Entropy std
    Œ±_Œ¥ ¬∑ œÉ_Œ¥(t) +  # Divergence std
    Œ≤ ¬∑ dRÃÑ/dt       # Acceleration term
)

# Abort if persistently high risk
if R(t) ‚â• œÑ_abort for K consecutive windows:
    prune_generation()
```

---

## üìê **Architecture-Specific Calibration**

Different models require different thresholds:

| Model | Œît (tokens) | œÑ_abort | K | AUC | Accuracy |
|-------|-------------|---------|---|-----|----------|
| **Phi-3** | 10 | 0.74 | 2 | 94.2% | 85% |
| **Mistral** | 12 | 0.71 | 2 | 87.1% | 70% |
| **Llama** | 12-15 | 0.68 | 3 | 79.1% | 61% |


---

## üß¨ **Empirical Signature of the Obsessive Attractor**

Hallucinations exhibit a characteristic observable pattern:

| Observable | Factual | Hallucination | Pattern |
|------------|---------|---------------|---------|
| Œ© (Entropy) | 0.443 | 0.389 | ‚Üì Lower |
| Œ∑ (Rigidity) | 0.557 | 0.611 | ‚Üë Higher |
| Œû (Diversity) | 0.042 | 0.028 | ‚Üì Lower |
| Œî (Divergence) | 0.557 | 0.611 | ‚Üë Higher |

**Interpretation:** Hallucinations = premature collapse onto spurious attractors with **high confidence + low entropy**.

---

## ‚ö†Ô∏è **Limitations**

Kappa-LLM does not claim to eliminate hallucinations. The framework focuses on:

- **Structural Risk Detection**: Identifying high-risk attention trajectories, not semantic verification
- **Early Mitigation**: Interrupting unstable generation before semantic failure
- **Bounded Accuracy**: Structurally stable generations may still be factually incorrect

**Key Understanding:** This is a trajectory-level structural control system, not a fact-checking oracle. The natural upper bound on binary accuracy reflects architectural stability constraints, not framework failure.

**What We Do:** Detect when attention dynamics become structurally unstable  
**What We Don't Do:** Verify factual correctness or eliminate all hallucinations

---
## üìö Citation

If you use this work, please cite:

```bibtex
@software{ohio2026kappa_llm,
  author       = {Ohio, David},
  title        = {Kappa-LLM: Multi-Observable Structural Detection and Real-Time Mitigation of Hallucinations in Large Language Models},
  year         = {2026},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.18529821},
  url          = {https://doi.org/10.5281/zenodo.18529821}
}
```

---

## ü§ù **Contributing**

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

### **Areas for Contribution**

- üîß Additional model integrations (GPT-4, Claude, Gemini)
- üìä Domain-specific benchmarks (medical, legal, financial)
- ‚ö° Performance optimizations
- üìñ Documentation improvements
- üß™ Additional observables (Œì - gradient flow)
  > Note: Gradient-based observables (Œì) are intentionally excluded from the current paper due to lack of empirical validation. Future work may explore optimization dynamics.

---

## üìú **License**


**Code:** This repository, including code, documentation, and theoretical materials,
is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.
See the LICENSE file for details.
üîó https://creativecommons.org/licenses/by/4.0/

Attribution: If you use, adapt, or build upon the Kappa Method or its observables (Œ©, Œ¶, Œ∑, Œû, Œî), please provide appropriate credit to the original author and cite the associated materials.



---

## üôè **Acknowledgments**

- **HaluEval dataset:** Liu et al. (2023).  
  https://github.com/RUCAIBox/HaluEval

- **Kappa Method theoretical foundation:** Ohio, David (2026).  
  https://github.com/odavidohio/Kappa-Method

---

## üìß **Contact**

**David Ohio**  
üìß Email: odavidohio@gmail.com  
üîó GitHub: [@odavidohio](https://github.com/odavidohio)  

---

## üîó **Related Work**

- **Kappa-EDU**: Educational dropout prediction using Kappa Method
- **Kappa-FIN**: Financial crisis detection via attention topology

---

## ‚≠ê **Star History**

If you find this work useful, please consider starring the repository!

[![Star History Chart](https://api.star-history.com/svg?repos=odavidohio/Kappa-Attention-Regimes&type=Date)](https://star-history.com/#odavidohio/Kappa-Attention-Regimes&Date)

---

## üìä **Project Stats**

![GitHub stars](https://img.shields.io/github/stars/odavidohio/Kappa-Attention-Regimes?style=social)
![GitHub forks](https://img.shields.io/github/forks/odavidohio/Kappa-Attention-Regimes?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/odavidohio/Kappa-Attention-Regimes?style=social)

---

**Built with ‚ù§Ô∏è for safe and reliable LLM deployment**

*Last updated: February 8, 2026*
