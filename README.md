
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Paper](https://img.shields.io/badge/Paper-PDF-red)](./papers/PAPER_KAPPA_LLM_EN.md)

# Kappa-LLM: Multi-Observable Structural Detection and Real-Time Mitigation of Hallucinations

*Kappa-Attention-Regimes â€” empirical application of the Kappa Method to LLM attention dynamics*



Official implementation of **"Kappa-LLM: Multi-Observable Structural Detection and Real-Time Mitigation of Hallucinations in Large Language Models"** using topology-aware observables

<p align="center">
  <img src="./figures/framework/kappa_framework_overview.png" alt="Kappa-LLM Framework" width="800"/>
</p>

---

## ğŸ¯ **Overview**

Kappa-LLM is a multi-observable framework for detecting and mitigating hallucinations in Large Language Models (LLMs) during generation. Rather than post-hoc fact-checking, we monitor **structural attention dynamics** in real-time and prune unsafe trajectories before semantic failure.

### **Key Features**

âœ… **Real-Time Detection**: Monitors attention dynamics during generation (<2% overhead)  
âœ… **Multi-Observable Framework**: 5 canonical observables (Î©, Î¦, Î·, Î, Î”) capture structural instability  
âœ… **Cross-Architecture**: Validated on Phi-3, Mistral-7B, Llama-3.1-8B  
âœ… **Production-Compatible**: Designed to integrate with HuggingFace `StoppingCriteria`
âœ… **Strong Performance**: 94.2% AUC (Phi-3), 85% accuracy, +36.5pp over baseline  

---

## ğŸ“Š **Main Results**

| Model | Kappa AUC | Accuracy | R-Score AUC | Improvement |
|-------|-----------|----------|-------------|-------------|
| **Phi-3 Mini** | 94.2% | 85.0% | 57.7% | **+36.5pp** |
| **Mistral-7B** | 87.1% | 70.0% | 58.3% | **+28.8pp** |
| **Llama-3.1-8B** | 79.1% | 61.0% | 57.7% | **+21.4pp** |

**Computational Overhead:** <2% (10-15ms per checkpoint on A100)

> **Note:** Binary accuracy is bounded by architectural stability and is not the primary objective of the framework. The goal is structural risk detection, not semantic verification.

> âš ï¸ API note: The real-time integration shown below reflects the intended
> interface for the first stable release. Current versions expose the detector
> as a scoring component over extracted attention windows.

---

## ğŸš€ **Quick Start**

### **Installation**

```bash
# Clone repository
git clone https://github.com/odavidohio/Kappa-Attention-Regimes.git
cd Kappa-Attention-Regimes

# Install dependencies
pip install -r requirements.txt

# Install package
pip install -e .
```

### **Basic Usage**

```python
from kappa_llm import KappaDetector
from transformers import AutoModelForCausalLM, AutoTokenizer

# Load model
model = AutoModelForCausalLM.from_pretrained("microsoft/Phi-3-mini-4k-instruct")
tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")

# Initialize Kappa detector
detector = KappaDetector(
    model=model,
    window_size=10,
    check_interval=5,
    tau_abort=0.74,  # Phi-3 calibrated threshold
    persistence_k=2
)

# Generate with real-time monitoring
prompt = "What is the capital of France?"
outputs = model.generate(
    tokenizer.encode(prompt, return_tensors="pt"),
    max_length=100,
    stopping_criteria=[detector]
)

# Check if generation was pruned
if detector.was_pruned:
    print(f"âš ï¸ Generation pruned at token {detector.prune_position}")
    print(f"ğŸ“Š Structural risk: {detector.final_risk:.3f}")
else:
    print(f"âœ… Generation completed safely")
    print(tokenizer.decode(outputs[0]))
```


## ğŸ“– **Documentation**

### **Papers**

- ğŸ“„ [English Paper](./papers/PAPER_KAPPA_LLM_EN.md) - Full methodological description
- ğŸ“„ [Portuguese Paper](./papers/PAPER_KAPPA_LLM_PT.md) - VersÃ£o completa em portuguÃªs

### **Examples**

- ğŸ’¡ [Basic Usage](./examples/basic_usage.py)

---

## ğŸ§ª **Reproducing Experiments**

### **HaluEval Dataset**

```bash
# Download HaluEval dataset
python experiments/download_halueval.py

# Run experiments (Phi-3)
python experiments/halueval/run_phi3.py \
    --model microsoft/Phi-3-mini-4k-instruct \
    --output ./experiments/results/phi3/

# Run experiments (Mistral)
python experiments/halueval/run_mistral.py \
    --model mistralai/Mistral-7B-Instruct-v0.2 \
    --output ./experiments/results/mistral/

# Run experiments (Llama)
python experiments/halueval/run_llama.py \
    --model meta-llama/Llama-3.1-8B-Instruct \
    --output ./experiments/results/llama/
```

### **Generate Figures**

```bash
# Generate all paper figures
python experiments/generate_figures.py \
    --results_dir ./experiments/results/ \
    --output_dir ./papers/figures/
```

---

## ğŸ”¬ **Method Overview**

### **The Five Observables**

Kappa-LLM computes five canonical observables from attention matrices:

| Observable | Symbol | Measures | AUC (Phi-3) |
|------------|--------|----------|-------------|
| **Entropy** | Î© | Attention mass distribution | 93.1% |
| **Persistence** | Î¦ | Topological structure (0-dim holes) | 58.0% |
| **Rigidity** | Î· | Semantic alignment stability | 93.1% |
| **Diversity** | Î | Head specialization | 69.3% |
| **Divergence** | Î” | Structural deviation from baseline | 93.1% |

### **Kappa Score**

```python
# Composite score combining all observables
K(t) = sigmoid(
    Î±_Î© Â· (1 - Î©(t)) +
    Î±_Î¦ Â· Î¦(t) +
    Î±_Î· Â· Î·(t) +
    Î±_Î Â· (1 - Î(t)) +
    Î±_Î” Â· Î”(t)
)
```

### **Real-Time Pruning**

Uses **second-order statistics** (observable variability) for early detection:

```python
# Structural risk estimation
R(t) = sigmoid(
    Î±_Î· Â· Ïƒ_Î·(t) +  # Rigidity std
    Î±_Ï‰ Â· Ïƒ_Ï‰(t) +  # Entropy std
    Î±_Î´ Â· Ïƒ_Î´(t) +  # Divergence std
    Î² Â· dRÌ„/dt       # Acceleration term
)

# Abort if persistently high risk
if R(t) â‰¥ Ï„_abort for K consecutive windows:
    prune_generation()
```

---

## ğŸ“ **Architecture-Specific Calibration**

Different models require different thresholds:

| Model | Î”t (tokens) | Ï„_abort | K | AUC | Accuracy |
|-------|-------------|---------|---|-----|----------|
| **Phi-3** | 10 | 0.74 | 2 | 94.2% | 85% |
| **Mistral** | 12 | 0.71 | 2 | 87.1% | 70% |
| **Llama** | 12-15 | 0.68 | 3 | 79.1% | 61% |


---

## ğŸ§¬ **Empirical Signature of the Obsessive Attractor**

Hallucinations exhibit a characteristic observable pattern:

| Observable | Factual | Hallucination | Pattern |
|------------|---------|---------------|---------|
| Î© (Entropy) | 0.443 | 0.389 | â†“ Lower |
| Î· (Rigidity) | 0.557 | 0.611 | â†‘ Higher |
| Î (Diversity) | 0.042 | 0.028 | â†“ Lower |
| Î” (Divergence) | 0.557 | 0.611 | â†‘ Higher |

**Interpretation:** Hallucinations = premature collapse onto spurious attractors with **high confidence + low entropy**.

---

## âš ï¸ **Limitations**

Kappa-LLM does not claim to eliminate hallucinations. The framework focuses on:

- **Structural Risk Detection**: Identifying high-risk attention trajectories, not semantic verification
- **Early Mitigation**: Interrupting unstable generation before semantic failure
- **Bounded Accuracy**: Structurally stable generations may still be factually incorrect

**Key Understanding:** This is a trajectory-level structural control system, not a fact-checking oracle. The natural upper bound on binary accuracy reflects architectural stability constraints, not framework failure.

**What We Do:** Detect when attention dynamics become structurally unstable  
**What We Don't Do:** Verify factual correctness or eliminate all hallucinations

---



---

## ğŸ¤ **Contributing**

We welcome contributions! Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

### **Areas for Contribution**

- ğŸ”§ Additional model integrations (GPT-4, Claude, Gemini)
- ğŸ“Š Domain-specific benchmarks (medical, legal, financial)
- âš¡ Performance optimizations
- ğŸ“– Documentation improvements
- ğŸ§ª Additional observables (Î“ - gradient flow)
  > Note: Gradient-based observables (Î“) are intentionally excluded from the current paper due to lack of empirical validation. Future work may explore optimization dynamics.

---

## ğŸ“œ **License**


**Code:** This repository, including code, documentation, and theoretical materials,
is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.
See the LICENSE file for details.
ğŸ”— https://creativecommons.org/licenses/by/4.0/

Attribution: If you use, adapt, or build upon the Kappa Method or its observables (Î©, Î¦, Î·, Î, Î”), please provide appropriate credit to the original author and cite the associated materials.



---

## ğŸ™ **Acknowledgments**

- **HaluEval dataset:** Liu et al. (2023).  
  https://github.com/RUCAIBox/HaluEval

- **Kappa Method theoretical foundation:** Ohio, David (2026).  
  https://github.com/odavidohio/Kappa-Method

---

## ğŸ“§ **Contact**

**David Ohio**  
ğŸ“§ Email: odavidohio@gmail.com  
ğŸ”— GitHub: [@odavidohio](https://github.com/odavidohio)  

---

## ğŸ”— **Related Work**

- **Kappa-EDU**: Educational dropout prediction using Kappa Method
- **Kappa-FIN**: Financial crisis detection via attention topology

---

## â­ **Star History**

If you find this work useful, please consider starring the repository!

[![Star History Chart](https://api.star-history.com/svg?repos=odavidohio/Kappa-Attention-Regimes&type=Date)](https://star-history.com/#odavidohio/Kappa-Attention-Regimes&Date)

---

## ğŸ“Š **Project Stats**

![GitHub stars](https://img.shields.io/github/stars/odavidohio/Kappa-Attention-Regimes?style=social)
![GitHub forks](https://img.shields.io/github/forks/odavidohio/Kappa-Attention-Regimes?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/odavidohio/Kappa-Attention-Regimes?style=social)

---

**Built with â¤ï¸ for safe and reliable LLM deployment**

*Last updated: February 8, 2026*
